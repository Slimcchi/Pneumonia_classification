{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Pneumonie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import imageio\n",
    "import random as rdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageOps\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import itertools  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'chest_xray/'\n",
    "train_path = os.path.join(dirname, 'chest_xray/train')\n",
    "train_nrml_pth = os.path.join(train_path, 'NORMAL')\n",
    "train_pnm_pth = os.path.join(train_path, 'PNEUMONIA')\n",
    "test_path = os.path.join(dirname, 'chest_xray/test')\n",
    "test_nrml_pth = os.path.join(test_path, 'NORMAL')\n",
    "test_pnm_pth = os.path.join(test_path, 'PNEUMONIA')\n",
    "val_path = os.path.join(dirname, 'chest_xray/val')\n",
    "val_nrml_pth = os.path.join(val_path, 'NORMAL')\n",
    "val_pnm_pth = os.path.join(val_path, 'PNEUMONIA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imgs(item_dir, num_imgs=25):\n",
    "    all_item_dirs = os.listdir(item_dir)\n",
    "    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_imgs]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for idx, img_path in enumerate(item_files):\n",
    "        plt.subplot(5, 5, idx+1)\n",
    "\n",
    "        img = plt.imread(img_path)\n",
    "        #print(img.shape)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthy people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(train_nrml_pth, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People with pnemonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(train_pnm_pth, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_h = 300\n",
    "img_size_w = 300\n",
    "\n",
    "input_shape = (img_size_h, img_size_w, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VGG16 Model with Keras library\n",
    "from keras.applications import VGG16\n",
    "\n",
    "def build_model(backbone, lr = 0.0001):\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=lr, decay=1e-5),\n",
    "        metrics=['acc']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "vgg16 = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape\n",
    ")\n",
    "\n",
    "model = build_model(vgg16 ,lr = 1e-4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing / Keras Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#augmentation configuration we will use for validation / testing set\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_size_h, img_size_w),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    #subset='training',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    seed = 1)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(img_size_h, img_size_w),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    #subset='validation',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    seed = 1)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_size_h, img_size_w),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamètres and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.001)\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience = 4, monitor = \"val_acc\", mode=\"max\", verbose = 2)\n",
    "\n",
    "callback = [learning_rate_reduction, early_stopping_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 5,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks = callback,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "model.save_weights(\"vgg16-example-pneumonia.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/vgg16') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model('saved_model/my_modelV2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots et prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datagenerator(generator):\n",
    "    data_list = []\n",
    "    data_class = []\n",
    "    batch_index = 0\n",
    "\n",
    "    while batch_index <= generator.batch_index:\n",
    "        data = generator.next()\n",
    "        data_list.append(data[0])\n",
    "        data_class.append(data[1])\n",
    "        batch_index = batch_index + 1\n",
    "\n",
    "    # now, data_array is the numeric data of whole images\n",
    "    train_data = np.concatenate(data_list)\n",
    "    train_labels = np.concatenate(data_class)\n",
    "    \n",
    "    return train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = get_datagenerator(test_generator)\n",
    "\n",
    "# Evaluation on test dataset\n",
    "test_loss, test_score = model.evaluate(test_data, test_labels, batch_size = batch_size)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = model.predict(test_data, batch_size = batch_size)\n",
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(test_labels, preds)\n",
    "fpr, tpr, thresholds2 = roc_curve(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g-')\n",
    "    plt.title('Precision vs. Recall')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.legend(['Precision', 'Recall'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title('FPR (False Positive rate) vs TPR (True Positive Rate)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.show()\n",
    "    \n",
    "plot_precision_recall(precisions, recalls, thresholds)\n",
    "plot_roc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=0)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_labels, preds)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names = test_generator.class_indices.keys()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du modèle sur quelques exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_illness(image_path):\n",
    "    imge = plt.imread(image_path)\n",
    "    plt.figure()\n",
    "\n",
    "    img = image.load_img(image_path, target_size=(img_size_h, img_size_w), grayscale = \"True\")\n",
    "    x = image.img_to_array(img) \n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "\n",
    "    classes = model.predict_classes(images, batch_size=10)\n",
    "    if classes[0][0] == 0:\n",
    "        textstr = \"Prediction: Healthy\"\n",
    "    else:\n",
    "        textstr = \"Prediction: Pneumonia\"\n",
    "\n",
    "    if ('chest_xray/chest_xray/test/NORMAL' in image_path):\n",
    "        texttruth = \"Truth: Healthy\"\n",
    "    else :\n",
    "        texttruth = \"Truth: Pneumonia\"\n",
    "        \n",
    "    plt.gcf().text(0.9, 0.4, textstr, fontsize=20)\n",
    "    plt.gcf().text(0.9, 0.6, texttruth, fontsize=20)\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "sampling_normal = rdm.sample(os.listdir(test_nrml_pth), k=k)\n",
    "sampling_pnm = rdm.sample(os.listdir(test_pnm_pth), k=k)\n",
    "\n",
    "for i in range(0,k):\n",
    "    \n",
    "    img_test_nrml = os.path.join(test_nrml_pth, sampling_normal[i])\n",
    "    img_test_ill = os.path.join(test_pnm_pth, sampling_pnm[i])\n",
    "    \n",
    "    imge = predict_illness(img_test_nrml)\n",
    "    imge = predict_illness(img_test_ill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
